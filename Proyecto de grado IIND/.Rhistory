library(fBasics)
options(warn = - 1)
# Manejo del directorio
getwd()
directorio <- "C:/Users/windows/Documents/GitHub/Problem_Set_1/Proyecto-de-grado-IIND/Proyecto de grado IIND/1. Datos"
setwd(directorio)
# Chequeo de los archivos del directorio
dir()
list.files()
## Importacion de los datos ------------------
install_formats() # Cuestiones de importacion de archivos del paquete rio
da <- import("6. Bogota_Promedio_Dias_Act_VAR_1.xlsx")
# Convertir la base de datos "da" a formato ts
da.ts <- ts(da[2:6], start = as.Date(2021), frequency = 365)
plot(da.ts)
# -----------------------------------------------------------
# Sección 2: Prueba de cointegración
# -----------------------------------------------------------
# Evaluará modelos VAR con hasta 7 retardos.
nivelka=VARselect(da.ts, lag.max = 7, type = "const")
nivelka$selection
# AIC(n)  HQ(n)  SC(n) FPE(n)
#   7      4      3      7
niv1=VARorder(da.ts)
# [9,]  8 4.0412 4.8637 4.3504   26.2241  0.3957
# Al nivel 8 aumenta el pvalue mas del 5%
# Pero se repite más el 3
# -----------------------------------------------------------
# Aplicamos la prueba de Johansen para la identificación de relaciones lineales
# entre las series, lo que nos indica la condición de cointegración.
johatest=ca.jo(da.ts, type = "trace", K=3, ecdet ="none", spec = "longrun")
summary(johatest)
# r = 0  | 623.11 66.49 70.60 78.87
# Como 623.11 > ... , el rango de la martiz es 0 entonces si estan cointegradas,
# Si hay un equilibrio a largo plazo.
# Hay cointregracion de rango completo.
# -----------------------------------------------------------
# Sección 3: Construcción modelo VECM
# -----------------------------------------------------------
# lag=3 --> Orden autorregresivo
# r=2   --> Nivel de autointegración
# El nivel de autointegración --> la cantidad de veces que se debe diferenciar
# la serie para que se vuelva estacionaria.
vecm1 = VECM(da.ts, lag=3, r=2, estim = ("ML"))
summary(vecm1)
# Error correction term 1
# El pm2.5 consigo mismo tiene un equilibrio en sus resagos.
# El pm2.5 con la tmp tiene un equilibrio en sus resagos.
# El pm2.5 con la radsolar NO tiene un equilibrio en sus resagos.
# El pm2.5 con la ws tiene un equilibrio en sus resagos.
# Error correction term 2
# El pm2.5 tiene una relación consigo mismo marginalmente.
# El pm2.5 tiene una relación con la tmp marginalmente.
# El pm2.5 tiene una relación con la radsolar marginalmente.
# El pm2.5 tiene una relación con la ws marginalmente.
# Intercepto
# Todas las variables participan en el equilibrio de largo plazo.
# El pm2.5 en su 1er rezago tiene correlación consigo mismo, con 1er rezago tmp y con 1er rezago pressure.
# ...
# -----------------------------------------------------------
# Sección 4: Diagnostico
# -----------------------------------------------------------
# Para ello funcionan con VAR, hay que transformar, pasar de un obj VECM a un obj VAR:
varmod1 = vec2var(johatest, r=1)
# correlación:
ade1 = serial.test(varmod1, lags.pt = 5, type = "BG")
ade1
# H0: datos independientes
# H1: datos dependientes.
# p-value = 2.109e-15 < 5%, se rechaza H0 y los datos dependientes.
# Existe una dependencia lineal entre los rezagos.
# Modelo de volatilidad autorregresivo condicionados - ARCH
hete1 = arch.test(varmod1, lags.multi = 15, multivariate.only = TRUE)
hete1
#H0: NO existe efecto ARCH
# H1: SI existe efecto ARCH
# Se rechaza H0, SI existe efecto ARCH hasta el q ésimo rezago
# Hay heterocedasticidad, pues la varianza de los errores no es constante a lo largo del tiempo.
# Justificar por que:
# - Limitaciones del modelo, pues no abarca la heterocedasticidad.
# - Variabilidad natural de las variables: Las variables ambientales tienden a
#   mostrar variaciones naturales que pueden ser más pronunciadas en ciertos
#   periodos que en otros. Por ejemplo, la radiación solar y la temperatura
#   pueden tener variaciones diarias y estacionales significativas, lo que
#   afecta la dispersión y concentración de PM2.5. Esta variabilidad inherente
#   puede llevar a cambios en la varianza de los errores del modelo a lo largo del tiempo.
# - Impactos de eventos no controlados: Eventos específicos como incendios
#   forestales, variaciones climáticas extremas, o actividades humanas no
#   regulares (como construcciones o tráfico intenso) pueden introducir cambios
#   abruptos en las condiciones ambientales, lo que se refleja en una mayor
#   volatilidad en los datos y, por ende, en la heterocedasticidad en el modelo.
# -----------------------------------------------------------
# Sección 5: Analisis Impulso - Respuesta: Impulse response
# -----------------------------------------------------------
m1irf = irf(varmod1, n.ahead = 30, boot = TRUE)
#predicción eje Y: es la var dependiente, acorde el impulso X.
plot(m1irf)
plot(pred)
#predicción eje Y: es la var dependiente, acorde el impulso X.
plot(m1irf)
plot(m1irf)
setwd(directorio)
# Chequeo de los archivos del directorio
dir()
list.files()
## Importacion de los datos ------------------
install_formats() # Cuestiones de importacion de archivos del paquete rio
da <- import("6. Bogota_Promedio_Dias_Act_VAR_1.xlsx")
# Convertir la base de datos "da" a formato ts
da.ts <- ts(da[2:6], start = as.Date(2021), frequency = 365)
plot(da.ts)
# Chequeo de los archivos del directorio
dir()
list.files()
## Importacion de los datos ------------------
install_formats() # Cuestiones de importacion de archivos del paquete rio
da <- import("6. Bogota_Promedio_Dias_Act_VAR_1.xlsx")
# Convertir la base de datos "da" a formato ts
da.ts <- ts(da[2:6], start = as.Date(2021), frequency = 365)
plot(da.ts)
# Evaluará modelos VAR con hasta 7 retardos.
nivelka=VARselect(da.ts, lag.max = 7, type = "const")
nivelka$selection
niv1=VARorder(da.ts)
# Aplicamos la prueba de Johansen para la identificación de relaciones lineales
# entre las series, lo que nos indica la condición de cointegración.
johatest=ca.jo(da.ts, type = "trace", K=3, ecdet ="none", spec = "longrun")
summary(johatest)
niv1=VARorder(da.ts)
summary(johatest)
vecm1 = VECM(da.ts, lag=3, r=2, estim = ("ML"))
# Limpiar el entorno
rm(list = ls())
## Librerias ------------------
library(pacman)
library(tidyverse) # Paquete grande de manipulacion
library(lubridate) # Paquete para manejo de fechas
library(skimr)     # Paquete para revision de datos
library(stargazer) # Paquete de tablas "bonitas", regs y estad desc
library(dplyr)     # Paquete parte de tidyverse donde esta mutate, select, filter, summarise...
library(rio)       # Paquete de importacion/exportacion de datos
library(gridExtra)
library(patchwork)
library(stats)
library(readxl)
library(writexl)
library(ggplot2)
library(officer)
library(flextable)
library(pscl)
library(corrplot)   # Para el gráfico de correlación
library(devtools)
library(fpp3)
library(tseries) # Importamos la librería de tserires para la aplicación de la prueba de Dickey Fuller.
library(PerformanceAnalytics)
library(fBasics)
library(tsDyn)
library(urca)
library(vars)
library(MTS)
library(xts)
library(quantmod)
library(stats)
library(fBasics)
library(ARDL)
library(urca)
library(TSstudio)
library(quantmod)
library(fields)
library(dygraphs)
options(warn = - 1)
# Manejo del directorio
getwd()
directorio <- "C:/Users/windows/Documents/GitHub/Problem_Set_1/Proyecto-de-grado-IIND/Proyecto de grado IIND/1. Datos"
setwd(directorio)
# Chequeo de los archivos del directorio
dir()
list.files()
## Importacion de los datos ------------------
install_formats() # Cuestiones de importacion de archivos del paquete rio
da <- import("6. Bogota_Promedio_Dias_Act_VAR_1.xlsx")
# Convertir la base de datos "da" a formato ts
da.ts <- ts(da[2:6], start = as.Date(2021), frequency = 365)
plot(da.ts)
#Selección automatica:
models <- auto_ardl(pm25 ~ pressure + tmp + radsolar + ws, data = da.ts, max_order = 6)
#Revisemos el top 20 de los mejores modelos según su critrio de información de Akaike
models$top_orders
#Procedemos a construir el modelo de regresión con la mejor combinación.
mod1 <- ardl(pm25 ~ pressure + tmp + radsolar+ ws, data = da.ts, order = c(6,6,6,6,6))
summary(mod1)
# Para la interpretación, podemos imprimir los rezagos correspondientes de cada variable que explican la respuesta.
mod1$full_formula
#Predicción del primer modelo sin tendencia:
stats::predict(mod1$fitted.values, 10)
p_pm25 <- autoplot(predict(mod1$fitted.values, h=10)) +
geom_line() +
labs(x = "Tiempo",
y = "PM2.5",
title = "Predicción del PM2.5") +
theme_minimal() +
theme(
plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),  # Centra y ajusta el título
axis.title = element_text(size = 14),  # Ajusta el tamaño de las etiquetas de los ejes
axis.text = element_text(size = 12),   # Ajusta el tamaño del texto de los ejes
plot.background = element_rect(fill = "white"),  # Cambia el fondo del gráfico
panel.grid.minor = element_blank()  # Elimina las líneas de cuadrícula menores
)
p_pm25
p_pm25 + geom_hline(yintercept = 15, color = "red")
# Exportar como PNG
ggsave("24. Predicción del PM2.5 desde 2021 hasta 2024.png",
plot = last_plot(),
path = "C:/Users/windows/Documents/GitHub/Problem_Set_1/Proyecto-de-grado-IIND/Proyecto de grado IIND/4. Gráficos",
width = 10, height = 6, units = "in", dpi = 300)
# Guardamos el mejor modelo obtenido en la sección anterior
modelo <- models$best_model
# Realizamos la prueba de hipotesis
# El parametro "case" igual a 2 verifica si existe relaciones a largo termino,
# con la combinación de (restricted constant, no linear trend).
bounds_f_test(modelo, case = 2)
# Multiplicadores a corto plazo
# sr_ short run
multipliers(modelo, type = "sr")
# Limpiar el entorno
rm(list = ls())
## Librerias ------------------
library(pacman)
library(tidyverse) # Paquete grande de manipulacion
library(lubridate) # Paquete para manejo de fechas
library(skimr)     # Paquete para revision de datos
library(stargazer) # Paquete de tablas "bonitas", regs y estad desc
library(dplyr)     # Paquete parte de tidyverse donde esta mutate, select, filter, summarise...
library(rio)       # Paquete de importacion/exportacion de datos
library(gridExtra)
library(patchwork)
library(stats)
library(readxl)
library(writexl)
library(ggplot2)
library(officer)
library(flextable)
library(pscl)
library(corrplot)   # Para el gráfico de correlación
library(devtools)
library(fpp3)
library(tseries) # Importamos la librería de tserires para la aplicación de la prueba de Dickey Fuller.
library(PerformanceAnalytics)
library(fBasics)
library(tsDyn)
library(urca)
library(vars)
library(MTS)
library(xts)
library(quantmod)
library(stats)
library(fBasics)
options(warn = - 1)
# Manejo del directorio
getwd()
directorio <- "C:/Users/windows/Documents/GitHub/Problem_Set_1/Proyecto-de-grado-IIND/Proyecto de grado IIND/1. Datos"
setwd(directorio)
# Chequeo de los archivos del directorio
dir()
list.files()
## Importacion de los datos ------------------
install_formats() # Cuestiones de importacion de archivos del paquete rio
da <- import("6. Bogota_Promedio_Dias_Act_VAR_1.xlsx")
# Convertir la base de datos "da" a formato ts
da.ts <- ts(da[2:6], start = as.Date(2021), frequency = 365)
plot(da.ts)
# Evaluará modelos VAR con hasta 7 retardos.
nivelka=VARselect(da.ts, lag.max = 7, type = "const")
nivelka$selection
niv1=VARorder(da.ts)
# Aplicamos la prueba de Johansen para la identificación de relaciones lineales
# entre las series, lo que nos indica la condición de cointegración.
johatest=ca.jo(da.ts, type = "trace", K=3, ecdet ="none", spec = "longrun")
summary(johatest)
summary(johatest)
vecm1 = VECM(da.ts, lag=3, r=2, estim = ("ML"))
summary(vecm1)
summary(vecm1)
# Para ello funcionan con VAR, hay que transformar, pasar de un obj VECM a un obj VAR:
varmod1 = vec2var(johatest, r=1)
# correlación:
ade1 = serial.test(varmod1, lags.pt = 5, type = "BG")
ade1
?VECM
# Aplicamos la prueba de Johansen para la identificación de relaciones lineales
# entre las series, lo que nos indica la condición de cointegración.
johatest=ca.jo(da.ts, type = "trace", K=8, ecdet ="none", spec = "longrun")
summary(johatest)
# Aplicamos la prueba de Johansen para la identificación de relaciones lineales
# entre las series, lo que nos indica la condición de cointegración.
johatest=ca.jo(da.ts, type = "trace", K=8, ecdet ="none", spec = "longrun")
summary(johatest)
vecm1 = VECM(da.ts, lag=3, r=2, estim = ("ML"))
summary(vecm1)
summary(johatest)
vecm1 = VECM(da.ts, lag=5, r=4, estim = ("ML"))
summary(vecm1)
# Para ello funcionan con VAR, hay que transformar, pasar de un obj VECM a un obj VAR:
varmod1 = vec2var(johatest, r=1)
# correlación:
ade1 = serial.test(varmod1, lags.pt = 5, type = "BG")
ade1
vecm1 = VECM(da.ts, lag=6, r=7, estim = ("ML"))
vecm1 = VECM(da.ts, lag=7, r=4, estim = ("ML"))
summary(vecm1)
# Para ello funcionan con VAR, hay que transformar, pasar de un obj VECM a un obj VAR:
varmod1 = vec2var(johatest, r=1)
# correlación:
ade1 = serial.test(varmod1, lags.pt = 5, type = "BG")
ade1
m1irf = irf(varmod1, n.ahead = 30, boot = TRUE)
#predicción eje Y: es la var dependiente, acorde el impulso X.
plot(m1irf)
library(tidyverse) # Paquete grande de manipulacion
library(lubridate) # Paquete para manejo de fechas
library(skimr)     # Paquete para revision de datos
library(stargazer) # Paquete de tablas "bonitas", regs y estad desc
library(dplyr)     # Paquete parte de tidyverse donde esta mutate, select, filter, summarise...
library(rio)       # Paquete de importacion/exportacion de datos
library(gridExtra)
library(patchwork)
library(stats)
library(readxl)
library(writexl)
library(ggplot2)
library(officer)
library(flextable)
library(pscl)
library(corrplot)   # Para el gráfico de correlación
library(devtools)
library(fpp3)
library(tseries) # Importamos la librería de tserires para la aplicación de la prueba de Dickey Fuller.
library(PerformanceAnalytics)
library(fBasics)
library(tsDyn)
library(urca)
library(vars)
library(MTS)
library(xts)
library(quantmod)
library(stats)
library(fBasics)
library(ARDL)
library(urca)
library(TSstudio)
library(quantmod)
library(fields)
library(dygraphs)
options(warn = - 1)
# Manejo del directorio
getwd()
directorio <- "C:/Users/windows/Documents/GitHub/Problem_Set_1/Proyecto-de-grado-IIND/Proyecto de grado IIND/1. Datos"
setwd(directorio)
# Chequeo de los archivos del directorio
dir()
list.files()
## Importacion de los datos ------------------
install_formats() # Cuestiones de importacion de archivos del paquete rio
# Limpiar el entorno
rm(list = ls())
## Librerias ------------------
library(pacman)
library(tidyverse) # Paquete grande de manipulacion
library(lubridate) # Paquete para manejo de fechas
library(skimr)     # Paquete para revision de datos
library(stargazer) # Paquete de tablas "bonitas", regs y estad desc
library(dplyr)     # Paquete parte de tidyverse donde esta mutate, select, filter, summarise...
library(rio)       # Paquete de importacion/exportacion de datos
library(gridExtra)
library(patchwork)
library(stats)
library(readxl)
library(writexl)
library(ggplot2)
library(officer)
library(flextable)
library(pscl)
library(corrplot)   # Para el gráfico de correlación
library(devtools)
library(fpp3)
library(tseries) # Importamos la librería de tserires para la aplicación de la prueba de Dickey Fuller.
library(PerformanceAnalytics)
library(fBasics)
library(tsDyn)
library(urca)
library(vars)
library(MTS)
library(xts)
library(quantmod)
library(stats)
library(fBasics)
library(ARDL)
library(urca)
library(TSstudio)
library(quantmod)
library(fields)
library(dygraphs)
options(warn = - 1)
# Manejo del directorio
getwd()
directorio <- "C:/Users/windows/Documents/GitHub/Problem_Set_1/Proyecto-de-grado-IIND/Proyecto de grado IIND/1. Datos"
setwd(directorio)
# Chequeo de los archivos del directorio
dir()
list.files()
## Importacion de los datos ------------------
install_formats() # Cuestiones de importacion de archivos del paquete rio
da <- import("6. Bogota_Promedio_Dias_Act_VAR_1.xlsx")
# Convertir la base de datos "da" a formato ts
da.ts <- ts(da[2:6], start = as.Date(2021), frequency = 365)
plot(da.ts)
#Selección automatica:
models <- auto_ardl(pm25 ~ pressure + tmp + radsolar + ws, data = da.ts, max_order = 6)
#Revisemos el top 20 de los mejores modelos según su critrio de información de Akaike
models$top_orders
#Procedemos a construir el modelo de regresión con la mejor combinación.
mod1 <- ardl(pm25 ~ pressure + tmp + radsolar+ ws, data = da.ts, order = c(6,6,6,6,6))
summary(mod1)
summary(mod1)
# Para la interpretación, podemos imprimir los rezagos correspondientes de cada variable que explican la respuesta.
mod1$full_formula
#Predicción del primer modelo sin tendencia:
stats::predict(mod1$fitted.values, 10)
p_pm25 <- autoplot(predict(mod1$fitted.values, h=10)) +
geom_line() +
labs(x = "Tiempo",
y = "PM2.5",
title = "Predicción del PM2.5") +
theme_minimal() +
theme(
plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),  # Centra y ajusta el título
axis.title = element_text(size = 14),  # Ajusta el tamaño de las etiquetas de los ejes
axis.text = element_text(size = 12),   # Ajusta el tamaño del texto de los ejes
plot.background = element_rect(fill = "white"),  # Cambia el fondo del gráfico
panel.grid.minor = element_blank()  # Elimina las líneas de cuadrícula menores
)
p_pm25
p_pm25 + geom_hline(yintercept = 15, color = "red")
# Exportar como PNG
ggsave("24. Predicción del PM2.5 desde 2021 hasta 2024.png",
plot = last_plot(),
path = "C:/Users/windows/Documents/GitHub/Problem_Set_1/Proyecto-de-grado-IIND/Proyecto de grado IIND/4. Gráficos",
width = 10, height = 6, units = "in", dpi = 300)
# Guardamos el mejor modelo obtenido en la sección anterior
modelo <- models$best_model
# Realizamos la prueba de hipotesis
# El parametro "case" igual a 2 verifica si existe relaciones a largo termino,
# con la combinación de (restricted constant, no linear trend).
bounds_f_test(modelo, case = 2)
?bounds_f_test
# Multiplicadores a corto plazo
# sr_ short run
multipliers(modelo, type = "sr")
# Como el modelo presenta cointegración, aplica:
bounds_f_test(modelo, case = 3)
# Multiplicadores a largo plazo
multipliers(modelo, type = "lr")
a <- resid(modelo)
pacf(a, 30)
checkresiduals(modelo)
?bounds_f_test
da_log <- da%>%mutate(across(everything(), log))
da_log <- da[2:6]%>%mutate(across(everything(), log))
View(da_log)
# Convertir la base de datos "da" a formato ts
da.ts <- ts(da_log[1:6], start = as.Date(2021), frequency = 365)
# Convertir la base de datos "da" a formato ts
da.ts <- ts(da_log[1:6], start = as.Date(2021), frequency = 365)
plot(da.ts)
checkresiduals(modelo)
#Procedemos a construir el modelo de regresión con la mejor combinación.
mod1 <- ardl(pm25 ~ pressure + tmp + radsolar+ ws, data = da.ts, lamda = TRUE ,order = c(6,6,6,6,6))
summary(mod1)
# Para la interpretación, podemos imprimir los rezagos correspondientes de cada variable que explican la respuesta.
mod1$full_formula
#Predicción del primer modelo sin tendencia:
stats::predict(mod1$fitted.values, 10)
p_pm25 <- autoplot(predict(mod1$fitted.values, h=10)) +
geom_line() +
labs(x = "Tiempo",
y = "PM2.5",
title = "Predicción del PM2.5") +
theme_minimal() +
theme(
plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),  # Centra y ajusta el título
axis.title = element_text(size = 14),  # Ajusta el tamaño de las etiquetas de los ejes
axis.text = element_text(size = 12),   # Ajusta el tamaño del texto de los ejes
plot.background = element_rect(fill = "white"),  # Cambia el fondo del gráfico
panel.grid.minor = element_blank()  # Elimina las líneas de cuadrícula menores
)
p_pm25
p_pm25 + geom_hline(yintercept = 15, color = "red")
# Exportar como PNG
ggsave("24. Predicción del PM2.5 desde 2021 hasta 2024.png",
plot = last_plot(),
path = "C:/Users/windows/Documents/GitHub/Problem_Set_1/Proyecto-de-grado-IIND/Proyecto de grado IIND/4. Gráficos",
width = 10, height = 6, units = "in", dpi = 300)
# Guardamos el mejor modelo obtenido en la sección anterior
modelo <- models$best_model
# Realizamos la prueba de hipotesis
# El parametro "case" igual a 2 verifica si existe relaciones a largo termino,
# con la combinación de (restricted constant, no linear trend).
bounds_f_test(modelo, case = 2)
#Selección automatica:
models <- auto_ardl(pm25 ~ pressure + tmp + radsolar + ws, data = da.ts, lamda = TRUE,max_order = 6)
#Revisemos el top 20 de los mejores modelos según su critrio de información de Akaike
models$top_orders
