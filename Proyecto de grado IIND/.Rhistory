rain_avg = mean(Precipitacion, na.rm = TRUE),
radsolar_avg = mean(RadSolar, na.rm = TRUE),
o3_avg = mean(OZONO, na.rm = TRUE),
no2_avg = mean(NO2, na.rm = TRUE),
pm25_avg = mean(PM25, na.rm = TRUE),
co_avg = mean(CO, na.rm = TRUE),
so2_avg = mean(SO2, na.rm = TRUE),
bc_avg = mean(BC, na.rm = TRUE),
co2_avg = mean(CO2, na.rm = TRUE)
)
Kennedy_Por_Dias <- Kennedy_Por_Dias %>%
left_join(promedios_diarios, by = c("myday" = "Dia")) %>%
mutate(
pm10 = if_else(is.na(pm10), pm10_avg, pm10),
tmp = if_else(is.na(tmp), tmp_avg, tmp),
ws = if_else(is.na(ws), ws_avg, ws),
rh = if_else(is.na(rh), rh_avg, rh),
rain = if_else(is.na(rain), rain_avg, rain),
radsolar = if_else(is.na(radsolar), radsolar_avg, radsolar),
o3 = if_else(is.na(o3), o3_avg, o3),
no2 = if_else(is.na(no2), no2_avg, no2),
pm25 = if_else(is.na(pm25), pm25_avg, pm25),
co = if_else(is.na(co), co_avg, co),
so2 = if_else(is.na(so2), so2_avg, so2),
bc = if_else(is.na(bc), bc_avg, bc),
co2 = if_else(is.na(co2), co2_avg, co2)
) %>%
select(-ends_with("_avg"))  # Elimina las columnas de promedios temporales
summary(Kennedy_Por_Dias)
# Guardar la salida del resumen estadístico en una variable
salida <- capture.output(summary(Kennedy_Por_Dias))
# Construir la ruta completa del archivo de Word
ruta_archivo <- "C:/Users/windows/Documents/GitHub/Problem_Set_1/Proyecto-de-grado-IIND/Proyecto de grado IIND/5. Salidas de R/11. Kennedy_Por_Dias.doc"
# Escribir la salida en el archivo de Word
writeLines(salida, ruta_archivo)
# Limpiar el entorno
rm(list = ls())
## Librerias ------------------
library(pacman)
# Limpiar el entorno
rm(list = ls())
## Librerias ------------------
library(pacman)
library(tidyverse) # Paquete grande de manipulacion
library(lubridate) # Paquete para manejo de fechas
library(skimr)     # Paquete para revision de datos
library(stargazer) # Paquete de tablas "bonitas", regs y estad desc
library(dplyr)     # Paquete parte de tidyverse donde esta mutate, select, filter, summarise...
library(rio)       # Paquete de importacion/exportacion de datos
library(gridExtra)
library(patchwork)
library(stats)
library(readxl)
# Manejo del directorio
getwd()
directorio <- "C:/Users/windows/Documents/GitHub/Problem_Set_1/Proyecto-de-grado-IIND/Proyecto de grado IIND/1. Datos"
setwd(directorio)
# Chequeo de los archivos del directorio
dir()
list.files()
# Importar datos
PuenteAranda_Por_Horas <- read_excel("1. Datos (2021 -2024) - Por Horas.xlsx",
sheet = "Puente Aranda")
PuenteAranda_Por_Dias <- read_excel("2. Datos (2021 -2024) - Diarios.xlsx")
# Calculo de promedios
promedios_diarios <- PuenteAranda_Por_Horas %>%
group_by(Dia) %>%
summarise(
pm10_avg = mean(PM10, na.rm = TRUE),
tmp_avg = mean(Temperatura, na.rm = TRUE),
ws_avg = mean(VelViento, na.rm = TRUE),
rh_avg = mean(HR, na.rm = TRUE),
rain_avg = mean(Precipitacion, na.rm = TRUE),
radsolar_avg = mean(RadSolar, na.rm = TRUE),
o3_avg = mean(OZONO, na.rm = TRUE),
no2_avg = mean(NO2, na.rm = TRUE),
pm25_avg = mean(PM25, na.rm = TRUE),
co_avg = mean(CO, na.rm = TRUE),
so2_avg = mean(SO2, na.rm = TRUE),
bc_avg = mean(BC, na.rm = TRUE),
PresionBaro_avg = mean(PresionBaro, na.rm = TRUE)
)
PuenteAranda_Por_Dias <- PuenteAranda_Por_Dias %>%
left_join(promedios_diarios, by = c("myday" = "Dia")) %>%
mutate(
pm10 = if_else(is.na(pm10), pm10_avg, pm10),
tmp = if_else(is.na(tmp), tmp_avg, tmp),
ws = if_else(is.na(ws), ws_avg, ws),
rh = if_else(is.na(rh), rh_avg, rh),
rain = if_else(is.na(rain), rain_avg, rain),
radsolar = if_else(is.na(radsolar), radsolar_avg, radsolar),
o3 = if_else(is.na(o3), o3_avg, o3),
no2 = if_else(is.na(no2), no2_avg, no2),
pm25 = if_else(is.na(pm25), pm25_avg, pm25),
co = if_else(is.na(co), co_avg, co),
so2 = if_else(is.na(so2), so2_avg, so2),
bc = if_else(is.na(bc), bc_avg, bc),
pressure = if_else(is.na(pressure), PresionBaro_avg, pressure)
) %>%
select(-ends_with("_avg"))  # Elimina las columnas de promedios temporales
summary(PuenteAranda_Por_Dias)
summary(PuenteAranda_Por_Dias)
# Guardar la salida del resumen estadístico en una variable
salida <- capture.output(summary(PuenteAranda_Por_Dias))
# Construir la ruta completa del archivo de Word
ruta_archivo <- "C:/Users/windows/Documents/GitHub/Problem_Set_1/Proyecto-de-grado-IIND/Proyecto de grado IIND/5. Salidas de R/12. PuenteAranda_Por_Dias.doc"
# Escribir la salida en el archivo de Word
writeLines(salida, ruta_archivo)
# Importar datos
Centro_Por_Horas <- read_excel("1. Datos (2021 -2024) - Por Horas.xlsx",
sheet = "Centro de Alto Rendimiento")
Centro_Por_Dias <- read_excel("2. Datos (2021 -2024) - Diarios.xlsx")
# Calculo de promedios
promedios_diarios <- Centro_Por_Horas %>%
group_by(Dia) %>%
summarise(
pm10_avg = mean(PM10, na.rm = TRUE),
tmp_avg = mean(Temperatura, na.rm = TRUE),
ws_avg = mean(VelViento, na.rm = TRUE),
rh_avg = mean(HR, na.rm = TRUE),
rain_avg = mean(Precipitacion, na.rm = TRUE),
radsolar_avg = mean(RadSolar, na.rm = TRUE),
o3_avg = mean(OZONO, na.rm = TRUE),
no2_avg = mean(NO2, na.rm = TRUE),
pm25_avg = mean(PM25, na.rm = TRUE),
co_avg = mean(CO, na.rm = TRUE),
so2_avg = mean(SO2, na.rm = TRUE),
bc_avg = mean(BC, na.rm = TRUE),
co2_avg = mean(CO2, na.rm = TRUE)
)
Centro_Por_Dias <- Centro_Por_Dias %>%
left_join(promedios_diarios, by = c("myday" = "Dia")) %>%
mutate(
pm10 = if_else(is.na(pm10), pm10_avg, pm10),
tmp = if_else(is.na(tmp), tmp_avg, tmp),
ws = if_else(is.na(ws), ws_avg, ws),
rh = if_else(is.na(rh), rh_avg, rh),
rain = if_else(is.na(rain), rain_avg, rain),
radsolar = if_else(is.na(radsolar), radsolar_avg, radsolar),
o3 = if_else(is.na(o3), o3_avg, o3),
no2 = if_else(is.na(no2), no2_avg, no2),
pm25 = if_else(is.na(pm25), pm25_avg, pm25),
co = if_else(is.na(co), co_avg, co),
so2 = if_else(is.na(so2), so2_avg, so2),
bc = if_else(is.na(bc), bc_avg, bc),
co2 = if_else(is.na(co2), co2_avg, co2)
) %>%
select(-ends_with("_avg"))  # Elimina las columnas de promedios temporales
summary(Centro_Por_Dias)
# Guardar la salida del resumen estadístico en una variable
salida <- capture.output(summary(Centro_Por_Dias))
# Construir la ruta completa del archivo de Word
ruta_archivo <- "C:/Users/windows/Documents/GitHub/Problem_Set_1/Proyecto-de-grado-IIND/Proyecto de grado IIND/5. Salidas de R/13. Centro_Por_Dias.doc"
# Escribir la salida en el archivo de Word
writeLines(salida, ruta_archivo)
# Limpiar el entorno
rm(list = ls())
## Librerias ------------------
library(pacman)
library(tidyverse) # Paquete grande de manipulacion
library(lubridate) # Paquete para manejo de fechas
library(skimr)     # Paquete para revision de datos
library(stargazer) # Paquete de tablas "bonitas", regs y estad desc
library(dplyr)     # Paquete parte de tidyverse donde esta mutate, select, filter, summarise...
library(rio)       # Paquete de importacion/exportacion de datos
library(gridExtra)
library(patchwork)
library(stats)
library(readxl)
library(writexl)
# Manejo del directorio
getwd()
directorio <- "C:/Users/windows/Documents/GitHub/Problem_Set_1/Proyecto-de-grado-IIND/Proyecto de grado IIND/1. Datos"
setwd(directorio)
# Chequeo de los archivos del directorio
dir()
list.files()
## Importacion de los datos ------------------
install_formats() # Cuestiones de importacion de archivos del paquete rio
Guaymaral_Por_Dias <- import("3.1 Guaymaral_Por_Dias.RDS")
MinAmbiente_Por_Dias <- import("3.2 MinAmbiente_Por_Dias.RDS")
Suba_Por_Dias <- import("3.3 Suba_Por_Dias.RDS")
Usaquen_Por_Dias <- import("3.4 Usaquen_Por_Dias.RDS")
Ferias_Por_Dias <- import("3.5 Ferias_Por_Dias.RDS")
SanCristobal_Por_Dias <- import("3.6 SanCristobal_Por_Dias.RDS")
Tunal_Por_Dias <- import("3.7 Tunal_Por_Dias.RDS")
Bolivia_Por_Dias <- import("3.8 Bolivia_Por_Dias.RDS")
Carvajal_Por_Dias <- import("3.9 Carvajal_Por_Dias.RDS")
Fontibon_Por_Dias <- import("3.10 Fontibon_Por_Dias.RDS")
Kennedy_Por_Dias <- import("3.11 Kennedy_Por_Dias.RDS")
PuenteAranda_Por_Dias <- import("3.12 PuenteAranda_Por_Dias.RDS")
Centro_Por_Dias <- import("3.13 Centro_Por_Dias.RDS")
# Unir todas las bases de datos en una sola
all_data <- rbind(Guaymaral_Por_Dias, MinAmbiente_Por_Dias, Suba_Por_Dias,
Usaquen_Por_Dias, Ferias_Por_Dias, SanCristobal_Por_Dias,
Tunal_Por_Dias, Bolivia_Por_Dias, Carvajal_Por_Dias,
Fontibon_Por_Dias, Kennedy_Por_Dias, PuenteAranda_Por_Dias,
Centro_Por_Dias)
#view(all_data)
str(all_data)
# Renombrar la variable "myday" como "day"
all_data$day <- all_data$myday
# Importar base vacia
Bogota_Promedio_Dias <- read_excel("2. Datos (2021 -2024) - Diarios.xlsx")
# Calcula los promedios diarios de cada contaminante y otras variables
promedios_diarios <- all_data %>%
group_by(day) %>%
summarise(across(.cols = c(o3, no2, pm25, co, so2, pm10, bc, tmp, rh, rain, radsolar, co2, pressure, ws), .fns = ~mean(.x, na.rm = TRUE)))
# Asegurándonos de que las fechas están en formato de fecha si no lo están
promedios_diarios$day <- as.Date(promedios_diarios$day)
Bogota_Promedio_Dias$myday <- as.Date(Bogota_Promedio_Dias$myday)
# Renombrar la columna de fecha en promedios_diarios para coincidir con Bogota_Promedio_Dias
promedios_diarios <- rename(promedios_diarios, myday = day)
# Uniendo los datos
Bogota_Promedio_Dias <- left_join(Bogota_Promedio_Dias, promedios_diarios, by = "myday")
head(Bogota_Promedio_Dias)
# Eliminar columnas que terminan en ".x" y están completamente vacías
Bogota_Promedio_Dias <- Bogota_Promedio_Dias %>%
select(-matches("\\.x$")) %>%
select_if(~ !all(is.na(.)))
# Verificar el resultado
str(Bogota_Promedio_Dias)
view(Bogota_Promedio_Dias)
# Renombrar variables quitando el sufijo ".y"
Bogota_Promedio_Dias <- Bogota_Promedio_Dias %>%
rename_with(~ gsub("\\.y$", "", .x), ends_with(".y"))
# Verificar los cambios
names(Bogota_Promedio_Dias)
summary(Bogota_Promedio_Dias)
summary(Bogota_Promedio_Dias)
summary(Bogota_Promedio_Dias)
# Guardar la salida del resumen estadístico en una variable
salida <- capture.output(summary(Bogota_Promedio_Dias))
# Construir la ruta completa del archivo de Word
ruta_archivo <- "C:/Users/windows/Documents/GitHub/Problem_Set_1/Proyecto-de-grado-IIND/Proyecto de grado IIND/5. Salidas de R/14. Bogota_Promedio_Dias.doc"
# Escribir la salida en el archivo de Word
writeLines(salida, ruta_archivo)
# Limpiar el entorno
rm(list = ls())
## Librerias ------------------
library(pacman)
library(tidyverse) # Paquete grande de manipulacion
library(lubridate) # Paquete para manejo de fechas
library(skimr)     # Paquete para revision de datos
library(stargazer) # Paquete de tablas "bonitas", regs y estad desc
library(dplyr)     # Paquete parte de tidyverse donde esta mutate, select, filter, summarise...
library(rio)       # Paquete de importacion/exportacion de datos
library(gridExtra)
library(patchwork)
library(stats)
library(readxl)
library(writexl)
library(ggplot2)
library(officer)
library(flextable)
library(pscl)
library(corrplot)   # Para el gráfico de correlación
library(devtools)
library(fpp3)
library(tseries) # Importamos la librería de tserires para la aplicación de la prueba de Dickey Fuller.
library(PerformanceAnalytics)
library(fBasics)
library(tsDyn)
library(urca)
library(vars)
library(MTS)
library(xts)
library(quantmod)
library(stats)
library(fBasics)
options(warn = - 1)
# Manejo del directorio
getwd()
directorio <- "C:/Users/windows/Documents/GitHub/Problem_Set_1/Proyecto-de-grado-IIND/Proyecto de grado IIND/1. Datos"
setwd(directorio)
# Chequeo de los archivos del directorio
dir()
list.files()
## Importacion de los datos ------------------
install_formats() # Cuestiones de importacion de archivos del paquete rio
da <- import("7. Bogota_Promedio_Dias_Act_VECM.xlsx")
# Convertir la base de datos "da" a formato ts
da.ts <- ts(da[2:6], start = as.Date(2021), frequency = 365)
plot(da.ts)
# Convertir la base de datos "da" a formato ts
da1.ts <- ts(da[2:6], start = as.Date(2021), frequency = 365)
plot(da1.ts)
str(da)
pm25=diff(gdp[,1],1)
# Limpiar el entorno
rm(list = ls())
## Librerias ------------------
library(pacman)
library(tidyverse) # Paquete grande de manipulacion
library(lubridate) # Paquete para manejo de fechas
library(skimr)     # Paquete para revision de datos
library(stargazer) # Paquete de tablas "bonitas", regs y estad desc
library(dplyr)     # Paquete parte de tidyverse donde esta mutate, select, filter, summarise...
library(rio)       # Paquete de importacion/exportacion de datos
library(gridExtra)
library(patchwork)
library(stats)
library(readxl)
library(writexl)
library(ggplot2)
library(officer)
library(flextable)
library(pscl)
library(corrplot)   # Para el gráfico de correlación
library(devtools)
library(fpp3)
library(tseries) # Importamos la librería de tserires para la aplicación de la prueba de Dickey Fuller.
library(PerformanceAnalytics)
library(fBasics)
library(tsDyn)
library(urca)
library(vars)
library(MTS)
library(xts)
library(quantmod)
library(stats)
library(fBasics)
options(warn = - 1)
# Manejo del directorio
getwd()
directorio <- "C:/Users/windows/Documents/GitHub/Problem_Set_1/Proyecto-de-grado-IIND/Proyecto de grado IIND/1. Datos"
setwd(directorio)
# Chequeo de los archivos del directorio
dir()
list.files()
## Importacion de los datos ------------------
install_formats() # Cuestiones de importacion de archivos del paquete rio
da <- import("7. Bogota_Promedio_Dias_Act_VECM.xlsx")
# Convertir la base de datos "da" a formato ts
da.ts <- ts(da[2:6], start = as.Date(2021), frequency = 365)
plot(da.ts)
# Evaluará modelos VAR con hasta 7 retardos.
nivelka=VARselect(da.ts, lag.max = 8, type = "const")
nivelka$selection
niv1=VARorder(da.ts)
# Aplicamos la prueba de Johansen para la identificación de relaciones lineales
# entre las series, lo que nos indica la condición de cointegración.
johatest=ca.jo(da.ts, type = "trace", K=8, ecdet ="none", spec = "longrun")
summary(johatest)
pm25=diff(da[,1],1)
tmp=diff((da[,2]),1)
radsolar=diff(da[,3],1)
pressure=diff(da[,4],1)
ws=diff(gdp[,5],1)
ws=diff(da[,5],1)
z=cbind.data.frame(pm25,tmp,radsolar,pressure,ws)
head(z)
View(z)
# Convertir la base de datos "da" a formato ts
da.ts <- ts(da[2:6], start = as.Date(2021), frequency = 365)
plot(da.ts)
# Evaluará modelos VAR con hasta 7 retardos.
nivelka=VARselect(da.ts, lag.max = 8, type = "const")
nivelka$selection
niv1=VARorder(da.ts)
# Aplicamos la prueba de Johansen para la identificación de relaciones lineales
# entre las series, lo que nos indica la condición de cointegración.
johatest=ca.jo(da.ts, type = "trace", K=8, ecdet ="none", spec = "longrun")
summary(johatest)
pm25=diff(da[,1],1)
tmp=diff((da[,2]),1)
radsolar=diff(da[,3],1)
pressure=diff(da[,4],1)
ws=diff(da[,5],1)
z=cbind.data.frame(pm25,tmp,radsolar,pressure,ws)
head(z)
pm25=diff(da.ts[,1],1)
tmp=diff((da.ts[,2]),1)
radsolar=diff(da.ts[,3],1)
pressure=diff(da.ts[,4],1)
ws=diff(da.ts[,5],1)
z=cbind.data.frame(pm25,tmp,radsolar,pressure,ws)
head(z)
str(z)
str(z)
str(z)
vecm1 = VECM(z, lag=7, r=4, estim = ("ML"))
summary(vecm1)
# Para ello funcionan con VAR, hay que transformar, pasar de un obj VECM a un obj VAR:
varmod1 = vec2var(johatest, r=1)
# correlación:
ade1 = serial.test(varmod1, lags.pt = 5, type = "BG")
ade1
# Modelo de volatilidad autorregresivo condicionados - ARCH
hete1 = arch.test(varmod1, lags.multi = 15, multivariate.only = TRUE)
hete1
m1irf = irf(varmod1, n.ahead = 30, boot = TRUE)
#predicción eje Y: es la var dependiente, acorde el impulso X.
plot(m1irf)
tmp=diff((da.ts[,2]),1)
radsolar=diff(da.ts[,3],1)
# Limpiar el entorno
rm(list = ls())
## Librerias ------------------
library(pacman)
library(tidyverse) # Paquete grande de manipulacion
library(lubridate) # Paquete para manejo de fechas
library(skimr)     # Paquete para revision de datos
library(stargazer) # Paquete de tablas "bonitas", regs y estad desc
library(dplyr)     # Paquete parte de tidyverse donde esta mutate, select, filter, summarise...
library(rio)       # Paquete de importacion/exportacion de datos
library(gridExtra)
library(patchwork)
library(stats)
library(readxl)
library(writexl)
library(ggplot2)
library(officer)
library(flextable)
library(pscl)
library(corrplot)   # Para el gráfico de correlación
library(devtools)
library(fpp3)
library(tseries) # Importamos la librería de tserires para la aplicación de la prueba de Dickey Fuller.
library(PerformanceAnalytics)
library(fBasics)
library(tsDyn)
library(urca)
library(vars)
library(MTS)
library(xts)
library(quantmod)
library(stats)
library(fBasics)
library(ARDL)
library(urca)
library(TSstudio)
library(quantmod)
library(fields)
library(dygraphs)
options(warn = - 1)
# Manejo del directorio
getwd()
directorio <- "C:/Users/windows/Documents/GitHub/Problem_Set_1/Proyecto-de-grado-IIND/Proyecto de grado IIND/1. Datos"
setwd(directorio)
# Chequeo de los archivos del directorio
dir()
list.files()
## Importacion de los datos ------------------
install_formats() # Cuestiones de importacion de archivos del paquete rio
da <- import("7. Bogota_Promedio_Dias_Act_VECM.xlsx")
# Convertir la base de datos "da" a formato ts
da.ts <- ts(da[2:6], start = as.Date(2021), frequency = 365)
plot(da.ts)
pm25=diff(da.ts[,1],1)
tmp=diff((da.ts[,2]),1)
radsolar=diff(da.ts[,3],1)
pressure=diff(da.ts[,4],1)
ws=diff(da.ts[,5],1)
z=cbind.data.frame(pm25,tmp,radsolar,pressure,ws)
head(z)
str(z)
#Selección automatica:
models <- auto_ardl(pm25 ~ pressure + tmp + radsolar + ws, data = da.ts, lamda = TRUE,max_order = 6)
#Selección automatica:
models <- auto_ardl(pm25 ~ pressure + tmp + radsolar + ws, data = z, lamda = TRUE,max_order = 6)
#Revisemos el top 20 de los mejores modelos según su critrio de información de Akaike
models$top_orders
#Procedemos a construir el modelo de regresión con la mejor combinación.
mod1 <- ardl(pm25 ~ pressure + tmp + radsolar+ ws, data = da.ts, lamda = TRUE ,order = c(6,6,6,6,6))
#Procedemos a construir el modelo de regresión con la mejor combinación.
mod1 <- ardl(pm25 ~ pressure + tmp + radsolar+ ws, data = z, lamda = TRUE ,order = c(6,6,6,6,6))
summary(mod1)
# Para la interpretación, podemos imprimir los rezagos correspondientes de cada variable que explican la respuesta.
mod1$full_formula
#Predicción del primer modelo sin tendencia:
stats::predict(mod1$fitted.values, 10)
p_pm25 <- autoplot(predict(mod1$fitted.values, h=10)) +
geom_line() +
labs(x = "Tiempo",
y = "PM2.5",
title = "Predicción del PM2.5") +
theme_minimal() +
theme(
plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),  # Centra y ajusta el título
axis.title = element_text(size = 14),  # Ajusta el tamaño de las etiquetas de los ejes
axis.text = element_text(size = 12),   # Ajusta el tamaño del texto de los ejes
plot.background = element_rect(fill = "white"),  # Cambia el fondo del gráfico
panel.grid.minor = element_blank()  # Elimina las líneas de cuadrícula menores
)
p_pm25
# Exportar como PNG
ggsave("24. Predicción del PM2.5 desde 2021 hasta 2024.png",
plot = last_plot(),
path = "C:/Users/windows/Documents/GitHub/Problem_Set_1/Proyecto-de-grado-IIND/Proyecto de grado IIND/4. Gráficos",
width = 10, height = 6, units = "in", dpi = 300)
# Guardamos el mejor modelo obtenido en la sección anterior
modelo <- models$best_model
# Realizamos la prueba de hipotesis
# El parametro "case" igual a 2 verifica si existe relaciones a largo termino,
# con la combinación de (restricted constant, no linear trend).
bounds_f_test(modelo, case = 2)
# Multiplicadores a corto plazo
# sr_ short run
multipliers(modelo, type = "sr")
# Como el modelo presenta cointegración, aplica:
bounds_f_test(modelo, case = 3)
# Multiplicadores a largo plazo
multipliers(modelo, type = "lr")
a <- resid(modelo)
pacf(a, 30)
library(tsDyn)
library(vars)
library(urca)
library(forecast)
library(tidyverse)
checkresiduals(modelo)
